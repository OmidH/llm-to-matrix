# Welcome to the sample config file
# Below you will find various config sections and options
# Default values are shown

# The string to prefix messages with to talk to the bot in group chats
command_prefix: "!c"

# Options for connecting to the bot's Matrix account
matrix:
  # The Matrix User ID of the bot account
  user_id: "@bot:example.com"
  # Matrix account password (optional if access token used)
  user_password: ""
  # Matrix account access token (optional if password used)
  #user_token: ""
  # The URL of the homeserver to connect to
  homeserver_url: https://example.com
  # The device ID that is **non pre-existing** device
  # If this device ID already exists, messages will be dropped silently in encrypted rooms
  device_id: ABCDEFGHIJ
  # What to name the logged in device
  device_name: llm-to-matrix

storage:
  # The database connection string
  # For SQLite3, this would look like:
  #     database: "sqlite://bot.db"
  # For Postgres, this would look like:
  #     database: "postgres://username:password@localhost/dbname?sslmode=disable"
  database: "sqlite://bot.db"
  # The path to a directory for internal bot storage
  # containing encryption keys, sync tokens, etc.
  store_path: "./store"

# Logging setup
logging:
  # Logging level
  # Allowed levels are 'INFO', 'WARNING', 'ERROR', 'DEBUG' where DEBUG is most verbose
  level: INFO
  # Configure logging to a file
  file_logging:
    # Whether logging to a file is enabled
    enabled: false
    # The path to the file to log to. May be relative or absolute
    filepath: bot.log
  # Configure logging to the console output
  console_logging:
    # Whether logging to the console is enabled
    enabled: true

# Default llm values
llm:
  llm_name: "Chatbot"
  llm_base_url: http://localhost:11434/ # http://host.docker.internal:11434/
  llm_url_suffix: "/api/generate"
  llm_tags_suffix: "/api/tags"
  llm_param_temp: 0.6
  llm_param_num_ctx: 8192
  llm_param_num_predict: -1
  llm_param_repeat_last_n: 64
  llm_param_repeat_penalty: 1.2
  llm_param_seed: 42
  llm_param_top_k: 40
  llm_param_top_p: 0.95
  llm_model: "mistral-7b-instruct:latest"
  llm_param_stop: 
    - "<|im_start|>user"
    - "</s>"
    - "<|user|>"
  llm_msg_template: "{message}"